# Sistema Inteligente de Matching Vaga-Candidato

## üìÑ Descri√ß√£o do Projeto

Este projeto apresenta um sistema avan√ßado de Machine Learning projetado para otimizar o processo de recrutamento e sele√ß√£o de talentos. O objetivo principal √© automatizar e aprimorar a compatibilidade entre candidatos e vagas dispon√≠veis, utilizando algoritmos de aprendizado de m√°quina para identificar os "melhores matches" com alta precis√£o. Em um cen√°rio onde o volume de candidaturas pode ser esmagador, esta ferramenta visa reduzir significativamente o tempo gasto por recrutadores na triagem manual, permitindo que se concentrem em intera√ß√µes mais estrat√©gicas com candidatos qualificados.

O sistema processa dados de curr√≠culos de candidatos e descri√ß√µes de vagas, transformando informa√ß√µes textuais e estruturadas em features num√©ricas que podem ser compreendidas por modelos de Machine Learning. A arquitetura do projeto √© modular, garantindo escalabilidade, manutenibilidade e reprodutibilidade de todo o pipeline de dados e modelagem. Desde o pr√©-processamento de dados brutos (JSONs) at√© a engenharia de features complexas, treinamento de modelos preditivos e avalia√ß√£o de performance, cada etapa √© cuidadosamente orquestrada para entregar resultados robustos e acion√°veis.

O resultado final √© uma aplica√ß√£o interativa constru√≠da com Streamlit, que oferece uma interface amig√°vel para recrutadores. Atrav√©s dela, √© poss√≠vel selecionar uma vaga espec√≠fica e visualizar uma lista ranqueada de candidatos com base em seu score de compatibilidade, permitindo uma tomada de decis√£o mais r√°pida e informada. Este sistema n√£o apenas acelera o processo de matching, mas tamb√©m busca introduzir uma camada de objetividade e consist√™ncia na avalia√ß√£o de candidatos, complementando a expertise humana com o poder da intelig√™ncia artificial.




## üõ†Ô∏è Stack Utilizada

Este projeto foi desenvolvido utilizando uma combina√ß√£o de tecnologias e bibliotecas Python, focando em robustez, efici√™ncia e facilidade de uso para o desenvolvimento de solu√ß√µes de Machine Learning e aplica√ß√µes web interativas. A escolha da stack reflete as melhores pr√°ticas em MLOps (Machine Learning Operations), garantindo um pipeline de dados e modelo bem estruturado e escal√°vel.

### Linguagem de Programa√ß√£o

*   **Python**: A linguagem principal utilizada em todo o projeto, desde o pr√©-processamento de dados at√© o desenvolvimento do modelo e da interface web. Sua vasta gama de bibliotecas e a comunidade ativa a tornam ideal para projetos de Machine Learning.

### Bibliotecas Principais

*   **Pandas**: Essencial para manipula√ß√£o e an√°lise de dados, utilizada extensivamente nas etapas de pr√©-processamento e engenharia de features. Facilita a leitura, limpeza, transforma√ß√£o e agrega√ß√£o de grandes volumes de dados.
*   **NumPy**: Fundamental para opera√ß√µes num√©ricas de alta performance, servindo como base para muitas outras bibliotecas cient√≠ficas em Python.
*   **Scikit-learn**: Uma biblioteca abrangente para Machine Learning, utilizada para tarefas como divis√£o de dados (treino/teste), pr√©-processamento (e.g., `MinMaxScaler`, `LabelEncoder`), e avalia√ß√£o de modelos (e.g., `roc_auc_score`, `f1_score`, `accuracy_score`, `classification_report`, `confusion_matrix`).
*   **LightGBM**: O algoritmo de Machine Learning escolhido para o treinamento do modelo preditivo. Conhecido por sua alta performance, velocidade e efici√™ncia no manuseio de grandes datasets, √© uma excelente escolha para problemas de classifica√ß√£o como o matching de vagas.
*   **Optuna**: Utilizado para a otimiza√ß√£o de hiperpar√¢metros do modelo LightGBM. Optuna √© uma biblioteca de otimiza√ß√£o autom√°tica de hiperpar√¢metros que permite encontrar as melhores configura√ß√µes para o modelo de forma eficiente, melhorando significativamente a performance.
*   **Streamlit**: Framework utilizado para construir a interface de usu√°rio interativa do sistema de matching. Permite transformar scripts Python em aplica√ß√µes web ricas e din√¢micas com poucas linhas de c√≥digo, ideal para prototipagem e demonstra√ß√µes r√°pidas.
*   **Boto3**: A SDK (Software Development Kit) da AWS para Python, utilizada para interagir com servi√ßos da Amazon Web Services, especificamente para carregar e salvar arquivos CSV no Amazon S3, garantindo o armazenamento escal√°vel e seguro dos dados processados.
*   **python-dotenv**: Utilizada para carregar vari√°veis de ambiente de um arquivo `.env`, facilitando o gerenciamento de credenciais e configura√ß√µes sens√≠veis (como chaves de acesso da AWS) sem exp√¥-las diretamente no c√≥digo-fonte.
*   **Joblib**: Biblioteca para serializa√ß√£o e desserializa√ß√£o de objetos Python, utilizada para salvar e carregar o modelo treinado (`model.pkl`) e as colunas do modelo (`model_columns.pkl`), permitindo que o modelo seja persistido e reutilizado sem a necessidade de retreinamento.
*   **Matplotlib** e **Seaborn**: Bibliotecas para cria√ß√£o de gr√°ficos e visualiza√ß√µes de dados. Embora a vers√£o final do Streamlit possa ter optado por gr√°ficos mais simples do pr√≥prio Streamlit, estas bibliotecas s√£o cruciais para a An√°lise Explorat√≥ria de Dados (EDA) e a visualiza√ß√£o de m√©tricas de avalia√ß√£o do modelo em notebooks de desenvolvimento.

### Gerenciamento de Depend√™ncias

*   **`requirements.txt`**: Um arquivo que lista todas as depend√™ncias do projeto, permitindo que o ambiente de desenvolvimento seja facilmente replicado em qualquer m√°quina.

### Estrutura de Projeto

O projeto segue uma estrutura modular, com pastas dedicadas para c√≥digo-fonte (`src`), dados (`data`), modelos (`models`), notebooks (`notebooks`), e a aplica√ß√£o Streamlit (`app`), promovendo a organiza√ß√£o e a manutenibilidade do c√≥digo.



## üöÄ Como Rodar o Aplicativo Localmente

Para executar a aplica√ß√£o Streamlit em sua m√°quina local, siga os passos abaixo. Certifique-se de que voc√™ tem o Python instalado (vers√£o 3.8+ √© recomendada).

### 1. Clonar o Reposit√≥rio

Primeiro, clone este reposit√≥rio para sua m√°quina local usando Git:

```bash
git clone https://github.com/usuario/BOSS_IA_Recrutamento.git
cd seu-repositorio
```

Substitua `https://github.com/seu-usuario/seu-repositorio.git` pelo URL real do seu reposit√≥rio no GitHub.

### 2. Configurar o Ambiente Virtual

√â altamente recomend√°vel usar um ambiente virtual para gerenciar as depend√™ncias do projeto. Isso evita conflitos com outras instala√ß√µes Python em sua m√°quina.

```bash
python -m venv venv
```

### 3. Ativar o Ambiente Virtual

*   **No Windows:**
    ```bash
    .\venv\Scripts\activate
    ```

*   **No macOS/Linux:**
    ```bash
    source venv/bin/activate
    ```

### 4. Instalar as Depend√™ncias

Com o ambiente virtual ativado, instale todas as bibliotecas necess√°rias listadas no `requirements.txt`:

```bash
pip install -r requirements.txt
```

### 5. Configurar Vari√°veis de Ambiente (AWS S3)

O aplicativo Streamlit l√™ os dados processados e com features do Amazon S3. Voc√™ precisar√° configurar suas credenciais AWS e o nome do bucket. Crie um arquivo `.env` na raiz do projeto com o seguinte conte√∫do:

```
AWS_ACCESS_KEY_ID=SUA_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY=SUA_SECRET_ACCESS_KEY
AWS_REGION_NAME=sua-regiao-aws # Ex: us-east-1
AWS_BUCKET_NAME=seu-nome-do-bucket-s3
```

Substitua os valores pelos seus pr√≥prios. **Nunca compartilhe este arquivo `.env` publicamente (ele j√° est√° no `.gitignore` para sua seguran√ßa).**

### 6. Treinar o Modelo (Primeira Vez ou Retreinamento)

Antes de rodar o aplicativo, voc√™ precisa garantir que o modelo foi treinado e que os arquivos `model.pkl` e `model_columns.pkl` (e os CSVs processados) existem. Se voc√™ ainda n√£o treinou o modelo ou se deseja retrein√°-lo com dados atualizados, execute o script `main.py`:

```bash
python -m src.main
```

Este script ir√°:
*   Pr√©-processar os dados brutos (JSONs).
*   Realizar a engenharia de features.
*   Treinar o modelo de Machine Learning.
*   Avaliar o desempenho do modelo.
*   Salvar o modelo treinado e as colunas utilizadas.

**Importante:** Este passo tamb√©m garante que os CSVs `preprocessed_data.csv` e `feature_engineered_data.csv` sejam gerados e, no seu caso, enviados para o S3, de onde o Streamlit os ler√°.

### 7. Rodar o Aplicativo Streamlit

Ap√≥s o treinamento do modelo e a configura√ß√£o das vari√°veis de ambiente, voc√™ pode iniciar o aplicativo Streamlit:

```bash
streamlit run src/app/app.py
```

O Streamlit abrir√° automaticamente o aplicativo em seu navegador padr√£o (geralmente em `http://localhost:8501`). Agora voc√™ pode interagir com o sistema de matching, selecionar vagas e visualizar os candidatos recomendados.



## üîÑ Como Treinar o Modelo Novamente

O processo de retreinamento do modelo √© integrado ao script principal do projeto (`src/main.py`). Sempre que voc√™ tiver novos dados ou desejar atualizar o modelo com as √∫ltimas informa√ß√µes, basta executar este script.

### Passos para Retreinar o Modelo:

1.  **Garanta que seus dados brutos estejam atualizados:** Certifique-se de que os arquivos JSON (`applicants.json`, `prospects.json`, `vagas.json`) na pasta `src/data/raw/` contenham as informa√ß√µes mais recentes que voc√™ deseja usar para o treinamento.

2.  **Execute o script principal:** Com seu ambiente virtual ativado (conforme os passos de instala√ß√£o acima), navegue at√© a raiz do projeto e execute:

    ```bash
    python -m src.main
    ```

    Este comando ir√°:
    *   Carregar os dados brutos atualizados.
    *   Executar todo o pipeline de pr√©-processamento e engenharia de features.
    *   Treinar um novo modelo de Machine Learning do zero, utilizando os dados mais recentes.
    *   Avaliar o desempenho do novo modelo.
    *   **Salvar o novo modelo treinado** (`model.pkl`) e as colunas utilizadas (`model_columns.pkl`) na pasta `src/models/`, sobrescrevendo as vers√µes anteriores.
    *   Os CSVs processados e com features (`preprocessed_data.csv`, `feature_engineered_data.csv`) tamb√©m ser√£o atualizados e, no seu caso, enviados para o S3.

Ap√≥s a conclus√£o bem-sucedida do `src/main.py`, seu aplicativo Streamlit (quando reiniciado ou acessado) automaticamente carregar√° o modelo rec√©m-treinado e os dados atualizados, refletindo as melhorias ou as novas informa√ß√µes incorporadas.

---